{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.regularizers import Regularizer\n",
    "from keras.objectives import kld\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked AE\n",
    "TODO\n",
    "- data generator for subsampled data for 4096 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_7 (Flatten)              (None, 1024)          0           flatten_input_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 100)           102500      flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 100)           10100       dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 4096)          413696      dense_23[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 526296\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Flatten(input_shape=(1, 32, 32)))\n",
    "autoencoder.add(Dense(100,activation='sigmoid'))\n",
    "autoencoder.add(Dense(100,activation='sigmoid'))\n",
    "autoencoder.add(Dense(4096,activation='sigmoid'))\n",
    "autoencoder.summary()\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training of W4 (unsupervised)\n",
    "- code for training\n",
    "- code for saving weights\n",
    "- save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the Kullback-Leibler divergence regularization\n",
    "\n",
    "class SparseActivityRegularizer(Regularizer):\n",
    "\n",
    "    def __init__(self, l1=0., l2=0.,p = 0.05,beta = 3):\n",
    "        self.l1 = K.cast_to_floatx(l1)\n",
    "        self.l2 = K.cast_to_floatx(l2)\n",
    "        self.uses_learning_phase = True\n",
    "        self.layer = None\n",
    "        self.p = p\n",
    "\n",
    "    def set_layer(self, layer):\n",
    "        if self.layer is not None:\n",
    "            raise Exception('Regularizers cannot be reused')\n",
    "        self.layer = layer\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.layer is None:\n",
    "            raise Exception('Need to call `set_layer` on '\n",
    "                            'ActivityRegularizer instance '\n",
    "                            'before calling the instance.')\n",
    "        regularized_loss = loss\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.layer.inbound_nodes)):\n",
    "            output = self.layer.get_output_at(i)\n",
    "            \n",
    "            p_hat = K.mean(output, axis=0)\n",
    "            regularized_loss += beta*K.sum(self.p * K.log(self.p / (p_hat+K.epsilon())))\n",
    "            \n",
    "        return K.in_train_phase(regularized_loss, loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'l1': float(self.l1),\n",
    "                'l2': float(self.l2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_9 (Flatten)              (None, 4096)          0           flatten_input_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 100)           409700      flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 4096)          413696      dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 823396\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lambd = 3e-3\n",
    "rho = 0.1\n",
    "beta = 3\n",
    "\n",
    "activity_regularizer = SparseActivityRegularizer(p=rho,beta=beta)\n",
    "\n",
    "h1 = Sequential()\n",
    "h1.add(Flatten(input_shape=(1, 64, 64)))\n",
    "h1.add(Dense(100,activation='sigmoid',W_regularizer=l2(lambd/2),activity_regularizer=activity_regularizer))\n",
    "h1.add(Dense(4096,W_regularizer=l2(lambd/2),activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "h1.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "h1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre training of W5 (unsupervised)\n",
    "- code for training\n",
    "- code for saving weights\n",
    "- save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_28 (Dense)                 (None, 100)           10100       dense_input_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 100)           10100       dense_28[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 20200\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lambd = 3e-3\n",
    "rho = 0.1\n",
    "beta = 3\n",
    "\n",
    "activity_regularizer = SparseActivityRegularizer(p=rho,beta=beta)\n",
    "\n",
    "h1 = Sequential()\n",
    "h1.add(Dense(100,activation='sigmoid',W_regularizer=l2(lambd/2),activity_regularizer=activity_regularizer,input_dim=100))\n",
    "h1.add(Dense(100,activation='sigmoid',W_regularizer=l2(lambd/2))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "h1.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "h1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre training of W6\n",
    "- code for training\n",
    "- code for saving weights\n",
    "- used with labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambd = 3e-3\n",
    "rho = 0.1\n",
    "beta = 3\n",
    "\n",
    "activity_regularizer = SparseActivityRegularizer(p=rho,beta=beta)\n",
    "\n",
    "h1 = Sequential()\n",
    "h1.add(Dense(4096,W_regularizer=l2(lambd/2),input_dim=100,activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "h1.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "h1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning of parameters\n",
    "- load weights into layers below\n",
    "- there is a 1/2 factor infront of the mse...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambd = 1e-4\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Flatten(input_shape=(1, 32, 32)))\n",
    "autoencoder.add(Dense(100,activation='sigmoid',W_regularizer=l2(lambd/2)))\n",
    "autoencoder.add(Dense(100,activation='sigmoid',W_regularizer=l2(lambd/2)))\n",
    "autoencoder.add(Dense(4096,activation='sigmoid',W_regularizer=l2(lambd/2)))\n",
    "autoencoder.summary()\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
